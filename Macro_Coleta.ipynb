{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8876af7e-4f0b-487a-bf1d-ef1b7937369b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os  \n",
    "import yfinance as yf\n",
    "from datetime import datetime\n",
    "import ipeadatapy as ipea "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab3b3c6-4b3f-48f5-9b4c-a328292df82f",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4ef9515-71b8-4713-90d7-3d7037251a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "CurDir=os.getcwd()\n",
    "path=CurDir+\"\\\\data\\\\\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4604b769",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Coleta_YF():\n",
    "    ativos=pd.read_csv(path+'Mercados.csv',sep ='\\t',encoding='utf-8')\n",
    "    tickers=list(ativos.Cod.values)\n",
    "    dados=yf.download(tickers,start='2015-01-01')['Adj Close']\n",
    "    return dados\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dba47425",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  125 of 125 completed\n"
     ]
    }
   ],
   "source": [
    "market=Coleta_YF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "10560fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "market.ffill().to_csv(path+'Dados_Mercados.csv', decimal='.', sep=';')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d36f4589-f469-4681-b084-90407679fcdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Coleta_periodo(periodo):\n",
    "    try:\n",
    "        Entrada=f'Dic_{periodo}_Macro.csv'\n",
    "        Saida=f'Macro_{periodo}.csv'\n",
    "        dados=pd.read_csv(path+Entrada, sep=';', index_col=0)\n",
    "        colunas=list(dados.Código.index)\n",
    "        ts=[pd.Series(ipea.timeseries(item).iloc[:,-1]) for item in list(dados.Código.values)]\n",
    "        \n",
    "        for item in range(len(colunas)): ts[item].name = colunas[item]\n",
    "        df=pd.DataFrame()\n",
    "        \n",
    "        for item in range(len(ts)):\n",
    "            df[colunas[item]]=ts[item].loc[~ts[item].index.duplicated(keep='first')]\n",
    "        \n",
    "        df.to_csv(path+Saida, decimal='.',sep=';')\n",
    "        \n",
    "        print ('Acabou')\n",
    "    except: print ('Algo deu errado')    \n",
    "    return "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2530f493-5fc2-4806-97e7-ebbca48e9841",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Séries Diárias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f29fe3cc-a6c9-4a74-ad91-881b1c2e02fb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dados_Diarios' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m colunas\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlist\u001b[39m(\u001b[43mdados_Diarios\u001b[49m\u001b[38;5;241m.\u001b[39mCódigos\u001b[38;5;241m.\u001b[39mindex)\n\u001b[0;32m      2\u001b[0m ts\u001b[38;5;241m=\u001b[39m[pd\u001b[38;5;241m.\u001b[39mSeries(ipea\u001b[38;5;241m.\u001b[39mtimeseries(item)\u001b[38;5;241m.\u001b[39miloc[:,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(dados_Diarios\u001b[38;5;241m.\u001b[39mCódigos\u001b[38;5;241m.\u001b[39mvalues)]\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(colunas)): ts[item]\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m=\u001b[39m colunas[item]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dados_Diarios' is not defined"
     ]
    }
   ],
   "source": [
    "colunas=list(dados_Diarios.Códigos.index)\n",
    "ts=[pd.Series(ipea.timeseries(item).iloc[:,-1]) for item in list(dados_Diarios.Códigos.values)]\n",
    "for item in range(len(colunas)): ts[item].name = colunas[item]\n",
    "\n",
    "df=pd.DataFrame()\n",
    "for item in range(len(ts)):\n",
    "    df[colunas[item]]=ts[item].loc[~ts[item].index.duplicated(keep='first')]\n",
    "\n",
    "df.to_csv(CurDir+'\\\\data\\\\'+'Macro_Diarios.csv', decimal='.',sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "368aa950-829a-4a0e-8c67-e329adb07549",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dados_Diarios' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m colunas\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlist\u001b[39m(\u001b[43mdados_Diarios\u001b[49m\u001b[38;5;241m.\u001b[39mCódigos\u001b[38;5;241m.\u001b[39mindex)\n\u001b[0;32m      2\u001b[0m ts\u001b[38;5;241m=\u001b[39m[pd\u001b[38;5;241m.\u001b[39mSeries(ipea\u001b[38;5;241m.\u001b[39mtimeseries(item)\u001b[38;5;241m.\u001b[39miloc[:,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(dados_Diarios\u001b[38;5;241m.\u001b[39mCódigos\u001b[38;5;241m.\u001b[39mvalues)]\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(colunas)): ts[item]\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m=\u001b[39m colunas[item]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dados_Diarios' is not defined"
     ]
    }
   ],
   "source": [
    "colunas=list(dados_Diarios.Códigos.index)\n",
    "ts=[pd.Series(ipea.timeseries(item).iloc[:,-1]) for item in list(dados_Diarios.Códigos.values)]\n",
    "for item in range(len(colunas)): ts[item].name = colunas[item]\n",
    "\n",
    "df=pd.DataFrame()\n",
    "for item in range(len(ts)):\n",
    "    df[colunas[item]]=ts[item].loc[~ts[item].index.duplicated(keep='first')]\n",
    "\n",
    "df.to_csv(CurDir+'\\\\data\\\\'+'Macro_Diarios.csv', decimal='.',sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad2efe6-e0d3-4e00-9f72-bed4f1eff49b",
   "metadata": {},
   "source": [
    "## Coleta Período"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "93d6e0fb-6e89-4510-8de3-cb6e405fc1a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_16908\\994727619.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[colunas[item]]=ts[item].loc[~ts[item].index.duplicated(keep='first')]\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_16908\\994727619.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[colunas[item]]=ts[item].loc[~ts[item].index.duplicated(keep='first')]\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_16908\\994727619.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[colunas[item]]=ts[item].loc[~ts[item].index.duplicated(keep='first')]\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_16908\\994727619.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[colunas[item]]=ts[item].loc[~ts[item].index.duplicated(keep='first')]\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_16908\\994727619.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[colunas[item]]=ts[item].loc[~ts[item].index.duplicated(keep='first')]\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_16908\\994727619.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[colunas[item]]=ts[item].loc[~ts[item].index.duplicated(keep='first')]\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_16908\\994727619.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[colunas[item]]=ts[item].loc[~ts[item].index.duplicated(keep='first')]\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_16908\\994727619.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[colunas[item]]=ts[item].loc[~ts[item].index.duplicated(keep='first')]\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_16908\\994727619.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[colunas[item]]=ts[item].loc[~ts[item].index.duplicated(keep='first')]\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_16908\\994727619.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[colunas[item]]=ts[item].loc[~ts[item].index.duplicated(keep='first')]\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_16908\\994727619.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[colunas[item]]=ts[item].loc[~ts[item].index.duplicated(keep='first')]\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_16908\\994727619.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[colunas[item]]=ts[item].loc[~ts[item].index.duplicated(keep='first')]\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_16908\\994727619.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[colunas[item]]=ts[item].loc[~ts[item].index.duplicated(keep='first')]\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_16908\\994727619.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[colunas[item]]=ts[item].loc[~ts[item].index.duplicated(keep='first')]\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_16908\\994727619.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[colunas[item]]=ts[item].loc[~ts[item].index.duplicated(keep='first')]\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_16908\\994727619.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[colunas[item]]=ts[item].loc[~ts[item].index.duplicated(keep='first')]\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_16908\\994727619.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[colunas[item]]=ts[item].loc[~ts[item].index.duplicated(keep='first')]\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_16908\\994727619.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[colunas[item]]=ts[item].loc[~ts[item].index.duplicated(keep='first')]\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_16908\\994727619.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[colunas[item]]=ts[item].loc[~ts[item].index.duplicated(keep='first')]\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_16908\\994727619.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[colunas[item]]=ts[item].loc[~ts[item].index.duplicated(keep='first')]\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_16908\\994727619.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[colunas[item]]=ts[item].loc[~ts[item].index.duplicated(keep='first')]\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_16908\\994727619.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[colunas[item]]=ts[item].loc[~ts[item].index.duplicated(keep='first')]\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_16908\\994727619.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[colunas[item]]=ts[item].loc[~ts[item].index.duplicated(keep='first')]\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_16908\\994727619.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[colunas[item]]=ts[item].loc[~ts[item].index.duplicated(keep='first')]\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_16908\\994727619.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[colunas[item]]=ts[item].loc[~ts[item].index.duplicated(keep='first')]\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_16908\\994727619.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[colunas[item]]=ts[item].loc[~ts[item].index.duplicated(keep='first')]\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_16908\\994727619.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[colunas[item]]=ts[item].loc[~ts[item].index.duplicated(keep='first')]\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_16908\\994727619.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[colunas[item]]=ts[item].loc[~ts[item].index.duplicated(keep='first')]\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_16908\\994727619.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[colunas[item]]=ts[item].loc[~ts[item].index.duplicated(keep='first')]\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_16908\\994727619.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[colunas[item]]=ts[item].loc[~ts[item].index.duplicated(keep='first')]\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_16908\\994727619.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[colunas[item]]=ts[item].loc[~ts[item].index.duplicated(keep='first')]\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_16908\\994727619.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[colunas[item]]=ts[item].loc[~ts[item].index.duplicated(keep='first')]\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_16908\\994727619.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[colunas[item]]=ts[item].loc[~ts[item].index.duplicated(keep='first')]\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_16908\\994727619.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[colunas[item]]=ts[item].loc[~ts[item].index.duplicated(keep='first')]\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_16908\\994727619.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[colunas[item]]=ts[item].loc[~ts[item].index.duplicated(keep='first')]\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_16908\\994727619.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[colunas[item]]=ts[item].loc[~ts[item].index.duplicated(keep='first')]\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_16908\\994727619.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[colunas[item]]=ts[item].loc[~ts[item].index.duplicated(keep='first')]\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_16908\\994727619.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[colunas[item]]=ts[item].loc[~ts[item].index.duplicated(keep='first')]\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_16908\\994727619.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[colunas[item]]=ts[item].loc[~ts[item].index.duplicated(keep='first')]\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_16908\\994727619.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[colunas[item]]=ts[item].loc[~ts[item].index.duplicated(keep='first')]\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_16908\\994727619.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[colunas[item]]=ts[item].loc[~ts[item].index.duplicated(keep='first')]\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_16908\\994727619.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[colunas[item]]=ts[item].loc[~ts[item].index.duplicated(keep='first')]\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_16908\\994727619.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[colunas[item]]=ts[item].loc[~ts[item].index.duplicated(keep='first')]\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_16908\\994727619.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[colunas[item]]=ts[item].loc[~ts[item].index.duplicated(keep='first')]\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_16908\\994727619.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[colunas[item]]=ts[item].loc[~ts[item].index.duplicated(keep='first')]\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_16908\\994727619.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[colunas[item]]=ts[item].loc[~ts[item].index.duplicated(keep='first')]\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_16908\\994727619.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[colunas[item]]=ts[item].loc[~ts[item].index.duplicated(keep='first')]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acabou\n",
      "Acabou\n"
     ]
    }
   ],
   "source": [
    "Coleta_periodo ('Mensais')\n",
    "Coleta_periodo ('Diarios')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f6380e-19f2-4c04-ad07-be870f7512d0",
   "metadata": {},
   "source": [
    "# Atualiza com última data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8788e95",
   "metadata": {},
   "source": [
    "diarios=pd.read_csv(CurDir+'\\\\data\\\\'+'Dic_Diarios_Macro.csv', sep=';', index_col=0)\n",
    "mensais=pd.read_csv(CurDir+'\\\\data\\\\'+'Dic_Mensais_Macro.csv', sep=';', index_col=0)\n",
    "trimestrais=pd.read_csv(CurDir+'\\\\data\\\\'+'Dic_Trimestrais_Macro.csv', sep=';', index_col=0)\n",
    "anuais=pd.read_csv(CurDir+'\\\\data\\\\'+'Dic_anuais_Macro.csv', sep=';', index_col=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "916914dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dados=pd.read_csv(CurDir+'\\\\data\\\\'+'Macro_Diarios.csv', sep=';', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "09338d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "último=dados.index[-1]\n",
    "codigos=pd.read_csv(CurDir+'\\\\data\\\\'+'Dic_Diarios_Macro.csv', sep=';', index_col=0).Código"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9b9167ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "codigos.index==dados.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c9c70b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "último='2024-12-18'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "6136c0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "ano=datetime.strptime(último,'%Y-%m-%d').year\n",
    "mes=datetime.strptime(último,'%Y-%m-%d').month\n",
    "dia=datetime.strptime(último,'%Y-%m-%d').day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "17a9af03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pega mesmo ano e mês e dayGreaterThan=dia\n"
     ]
    }
   ],
   "source": [
    "ipea.timeseries(codigos.values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "878f5ceb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CODE</th>\n",
       "      <th>RAW DATE</th>\n",
       "      <th>DAY</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>VALUE ((% a.a.))</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DATE</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-12-19</th>\n",
       "      <td>BM366_TJOVER366</td>\n",
       "      <td>2024-12-19T00:00:00-03:00</td>\n",
       "      <td>19</td>\n",
       "      <td>12</td>\n",
       "      <td>2024</td>\n",
       "      <td>12.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       CODE                   RAW DATE  DAY  MONTH  YEAR  \\\n",
       "DATE                                                                       \n",
       "2024-12-19  BM366_TJOVER366  2024-12-19T00:00:00-03:00   19     12  2024   \n",
       "\n",
       "            VALUE ((% a.a.))  \n",
       "DATE                          \n",
       "2024-12-19             12.25  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ipea.timeseries(codigos.values[0], year=ano, month=mes, dayGreaterThan=dia)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b22f5d",
   "metadata": {},
   "source": [
    "# Data Warehouse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5918bd5b",
   "metadata": {},
   "source": [
    "## Pega Séries ativas, cria coluna de temas e salva Data WareHouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "84575e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_Warehouse=ipea.metadata().loc[ipea.metadata()['SERIES STATUS']=='A']\n",
    "temas=ipea.themes().set_index(ipea.themes().ID).drop('ID',axis=1)\n",
    "Data_Warehouse['THEME']=temas.loc[Data_Warehouse['THEME CODE']].NAME.values\n",
    "Data_Warehouse.to_csv(CurDir+'\\\\data\\\\'+'Data_WareHouse.csv', decimal='.',sep=';')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prospero",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
